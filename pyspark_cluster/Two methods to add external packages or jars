There are two methods to add external packages to our sparksession, packages or jars. Guides: https://www.youtube.com/watch?v=5VcO01f3uQY

1. If our cluster is able to connect the internet, we can use the packages to add external packages.
e.g., Let us assume we want to add the package of reading a csv file to our sparksession. Then, we can achieve that in our notebook with the following codes.

import os
os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-csv_2.10:1.3.0 pyspark-shell'
import findspark
findspark.init('D:/Software/Study/Spark/spark-3.1.3-bin-hadoop3.2')
import pyspark

from pyspark.sql import SQLContext
sqlContext = SQLContext(sc)

df = sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('D:/Programming/Python/GEOG770/Project/data/input_vertices_1_pt.csv')

2. If our cluster is not able to connect to the internet, we can download the jars and config that in our codes like the following. The jars should be uploaded to the directory where the codes is located in.

import time
import numpy as np
import math
import findspark
findspark.init('D:/Software/Study/Spark/spark-3.1.3-bin-hadoop3.2')
from pyspark.sql import SparkSession

from sedona.register import SedonaRegistrator
from sedona.utils import SedonaKryoRegistrator, KryoSerializer

# configure Sparksession environment
spark = SparkSession.\
    builder.\
    master("local[*]").\
    appName("Add_jars").\
    config("spark.serializer", KryoSerializer.getName).\
    config("spark.kryo.registrator", SedonaKryoRegistrator.getName) .\
    config("spark.jars", "spark-csv_2.10-1.3.0.jar") .\
    config("spark.jars.packages", "org.apache.sedona:sedona-python-adapter-3.0_2.12:1.1.0-incubating,org.datasyslab:geotools-wrapper:1.1.0-25.2") .\
    getOrCreate()

# Register function is essential for Apache Sedona Core and Apache Sedona SQL. 
SedonaRegistrator.registerAll(spark)

from pyspark.sql import SQLContext
sqlContext = SQLContext(spark)
df = sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('D:/Programming/Python/GEOG770/Project/data/input_vertices_1_pt.csv')
